{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aimed at mapping global importance values to clusters.\n",
    "SST, swvl4, t850 and snowc are interesting for respagg 31 > q0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "sys.path.append(os.path.expanduser('~/Documents/Weave'))\n",
    "from Weave.utils import collapse_restore_multiindex, get_nhplus, get_nhmin, get_nhblock, get_europe\n",
    "from Weave.models import HybridExceedenceModel\n",
    "\n",
    "from Weave.inspection import ImportanceData, MapInterface, mapplot, FacetMapResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest results:\n",
    "quantile = 0.666 # options: 0.666 and 0.8\n",
    "model = HybridExceedenceModel(fit_base_to_all_cv = True, base_only = False, n_jobs = 15, max_depth = 5, min_samples_split = 30, n_estimators = 2500, max_features = 35)\n",
    "respagg = 31\n",
    "separation = -15\n",
    "\n",
    "basepath = Path('/nobackup_1/users/straaten/')\n",
    "inputpath = basepath / 'clusters_cv_spearmanpar_varalpha_strict' # Latest dimreduced X and y data \n",
    "anompath = basepath / 'processed'\n",
    "\n",
    "permtrainpath = basepath / f'permimp_train_q0{str(quantile)[2:]}'\n",
    "permtrain = ImportanceData(permtrainpath, respagg, separation, quantile, model)\n",
    "permtrain.load_data(inputpath=inputpath, X_too = True, y_too = True)\n",
    "permtrain.scale_within(fill_na = True)\n",
    "\n",
    "shaptrainpath = basepath / f'shap_stdback_train_q0{str(quantile)[2:]}'\n",
    "shaptrain = ImportanceData(shaptrainpath, respagg, separation, quantile, model)\n",
    "shaptrain.load_data(inputpath=inputpath, X_too = True, y_too = True)\n",
    "shaptrain.global_shap()\n",
    "shaptrain.df = shaptrain.df * 100\n",
    "\n",
    "shapvalpath = basepath / f'shap_stdback_val_q0{str(quantile)[2:]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustration data\n",
    "Tcc chosen for its slight (not large separation) importance. And consistency of correlation patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate(listofarrays, how: str = 'max', min_folds: int = None):\n",
    "    \"\"\"\n",
    "    Tries to remove the fold dimension. By counting how many times each cell in the fold, and getting the mean or max.\n",
    "    returns list of two dataarrays (first count, second the summary statistic).\n",
    "    \"\"\"\n",
    "    stacked = xr.concat(listofarrays, dim = 'fold')\n",
    "    count = stacked.count(dim = 'fold')\n",
    "    count = count.where(count != 0, np.nan)\n",
    "    count.name = 'count'\n",
    "    count.attrs.update(dict(units = \"\"))\n",
    "    f = getattr(stacked, how)\n",
    "    stat = f(dim = 'fold')\n",
    "    if not min_folds is None:\n",
    "        stat = stat.where(count >= min_folds, np.nan) # where larger or equal, keep the value\n",
    "    stat.name = how\n",
    "    stat.attrs.update(dict(units = \"\"))\n",
    "    return [count, stat]\n",
    "\n",
    "def makemaps(mapint, imps: pd.Series, inputtimescale = 31, acckwargs = dict(how = 'max', min_folds = None)):\n",
    "    variables = ['sst_nhplus', 't850_nhblock','snowc_nhmin','siconc_nhmin'] # 'swvl4_europe'\n",
    "    new_list = [] # will be dimension of variables\n",
    "    for var in variables:\n",
    "        if var == 't850_nhblock':\n",
    "            metricsep = imps.index.get_loc_level('mean','metric')[0]\n",
    "        else:\n",
    "            metricsep = imps.index.get_loc_level('spatcov','metric')[0]\n",
    "        frame = imps.loc[metricsep].loc[(slice(None),slice(None),[var],[31])]\n",
    "        maps = mapint_perm.map_to_fields(frame)\n",
    "        new_list.append(accumulate(maps.listofarrays, **acckwargs))\n",
    "    return FacetMapResult(rowkeys = variables, listofarrays = new_list, columnkeys = ['count',acckwargs['how']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapint_perm = MapInterface(corclustpath=inputpath, anompath= anompath, impdata=permtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "permimps = makemaps(mapint_perm, imps = permtrain.df[('multipass','rank')], acckwargs = dict(how = 'mean', min_folds = 4))\n",
    "#mapplot(permimps)\n",
    "shaps = makemaps(mapint_perm, imps = shaptrain.df['avgabsshap'], acckwargs=dict(how = 'mean', min_folds = 4))\n",
    "#mapplot(shaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_pcolormesh(array):\n",
    "    \"\"\"Xarray array to usuable things\"\"\"\n",
    "    lats = array.latitude.values # Interpreted as northwest corners (90 is in there)\n",
    "    lons = array.longitude.values # Interpreted as northwest corners (-180 is in there, 180 not)\n",
    "    lats = np.concatenate([lats[[0]] - np.diff(lats)[0], lats], axis = 0) # Adding the sourthern edge \n",
    "    lons = np.concatenate([lons, lons[[-1]] + np.diff(lons)[0]], axis = 0)# Adding the eastern edge\n",
    "    return lons, lats, array.values\n",
    "\n",
    "region = get_nhplus()\n",
    "extent = np.array(region[1:])[[1,3,2,0]]  # (-180,180,-40,80) drop the name and reorder to x0,x1,y0,y1\n",
    "#region_t850 = get_nhblock()\n",
    "#extent_t850 = np.array(region_t850[1:])[[1,3,2,0]] \n",
    "region_snow = get_nhmin()\n",
    "extent_snow = np.array(region_snow[1:])[[1,3,2,0]]  # drop the name and reorder to x0,x1,y0,y1\n",
    "extent_siconc = (-180,180,65,90)  # drop the name and reorder to x0,x1,y0,y1\n",
    "array_crs = ccrs.PlateCarree()\n",
    "proj = ccrs.Robinson() #ccrs.PlateCarree() #ccrs.Mollweide()\n",
    "proj_snow = ccrs.Orthographic(0,90)\n",
    "snowrow = permimps.rowkeys.index('snowc_nhmin')\n",
    "siconcrow = permimps.rowkeys.index('siconc_nhmin')\n",
    "#t850row = permimps.rowkeys.index('t850_nhblock')\n",
    "\n",
    "fig = plt.figure(figsize = (12,9))\n",
    "nvars = len(permimps.listofarrays)\n",
    "gs = GridSpec(ncols=3, nrows = nvars + 1, hspace = .05, wspace = 0.03, height_ratios=[0.9,0.9,1.2,1.2,0.1])\n",
    "axes = np.full((nvars,gs.ncols),None, dtype = 'object')\n",
    "ims = np.full((nvars,gs.ncols),None, dtype = 'object')\n",
    "for rowind,colind in itertools.product(range(axes.shape[0]),range(axes.shape[1])):\n",
    "    if rowind == snowrow:\n",
    "        axes[rowind,colind] = fig.add_subplot(gs[rowind,colind],projection=proj_snow)\n",
    "        axes[rowind,colind].set_extent(tuple(extent_snow), crs = array_crs)\n",
    "    elif rowind == siconcrow:\n",
    "        axes[rowind,colind] = fig.add_subplot(gs[rowind,colind],projection=proj_snow)\n",
    "        axes[rowind,colind].set_extent(tuple(extent_siconc), crs = array_crs)\n",
    "    #elif rowind == t850row:\n",
    "    #    axes[rowind,colind] = fig.add_subplot(gs[rowind,colind],projection=proj)\n",
    "    #    axes[rowind,colind].set_extent(tuple(extent_t850), crs = array_crs)\n",
    "    else:\n",
    "        axes[rowind,colind] = fig.add_subplot(gs[rowind,colind],projection=proj)\n",
    "        axes[rowind,colind].set_extent(tuple(extent), crs = array_crs)\n",
    "    if colind == 0:\n",
    "        field = permimps.listofarrays[rowind][colind]\n",
    "        vmin, vmax = (0,5) # Counts\n",
    "    elif colind == 1:\n",
    "        field = permimps.listofarrays[rowind][1]\n",
    "        vmin, vmax = (0,1) # scaled multipass\n",
    "    else:\n",
    "        field = shaps.listofarrays[rowind][1]\n",
    "        vmin, vmax = (0,4) # shap (multiplied by 100)\n",
    "    #axes[rowind,colind].stock_img()\n",
    "    axes[rowind,colind].add_feature(cfeature.OCEAN, zorder=0)\n",
    "    axes[rowind,colind].add_feature(cfeature.LAND, zorder=0, color = 'olivedrab', alpha = 0.8)\n",
    "    #axes[rowind,colind].coastlines(color = 'black', zorder = 0)\n",
    "    ims[rowind,colind] = axes[rowind,colind].pcolormesh(*data_for_pcolormesh(field), zorder = 1, shading = 'flat', transform = array_crs, cmap = 'plasma', vmin = vmin, vmax = vmax)\n",
    "\n",
    "cax_count = fig.add_subplot(gs[-1,0])\n",
    "cbar_count = fig.colorbar(ims[-1,0], cax = cax_count, orientation = 'horizontal', label = 'number of folds')\n",
    "cax_perm = fig.add_subplot(gs[-1,1])\n",
    "cbar_perm = fig.colorbar(ims[-1,1], cax = cax_perm, orientation = 'horizontal', label = 'permutation importance [rank]')\n",
    "cax_shap = fig.add_subplot(gs[-1,2])\n",
    "cbar_shap = fig.colorbar(ims[-1,2], cax = cax_shap, orientation = 'horizontal', label = 'TreeSHAP contribution [%]', extend = 'max')\n",
    "\n",
    "plt.savefig('/usr/people/straaten/Pictures/global_geo_imp.png', dpi = 140)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile = 0.666\n",
    "model = HybridExceedenceModel(fit_base_to_all_cv = True, base_only = False, n_jobs = 7, max_depth = 5, min_samples_split = 30, n_estimators = 2500, max_features = 35)\n",
    "shaps = ImportanceData(shapvalpath, respagg=[31], separation= [-15], quantile = quantile, model=model)\n",
    "shaps.load_data(X_too = True, y_too = True, inputpath = inputpath)\n",
    "mapint = MapInterface(corclustpath=inputpath, anompath= anompath, impdata=shaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer = '2015'\n",
    "moment1 = pd.Timestamp(f'{summer}-06-06')\n",
    "moment2 = pd.Timestamp(f'{summer}-07-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_sample1 = shaps.df.loc[([31],[4],['sst_nhplus'],[31,21],slice(None),[-15],[1,4],'spatcov'),[moment1]]\n",
    "sst_sample1 = sst_sample1.iloc[[0,-1],:] # Bit of a shortcut to select only those clustid combinations\n",
    "sst_maps1 = mapint.get_anoms(imp=sst_sample1, mask_with_clustid=True, mask_strict = True)\n",
    "siconc_sample1 = shaps.df.loc[([31],[4],['siconc_nhmin'],[31],slice(None),[-15],1,'spatcov'),[moment1]]\n",
    "siconc_maps1 = mapint.get_anoms(imp=siconc_sample1, mask_with_clustid=True, mask_strict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_sample = shaps.df.loc[([31],[4],['sst_nhplus'],[31,21],slice(None),[-15],[1,4],'spatcov'),[moment2]]\n",
    "sst_sample = sst_sample.iloc[[0,-1],:]\n",
    "sst_maps = mapint.get_anoms(imp=sst_sample, mask_with_clustid=True, mask_strict = True)\n",
    "siconc_sample = shaps.df.loc[([31],[4],['siconc_nhmin'],[31],slice(None),[-15],1,'spatcov'),[moment2]]\n",
    "siconc_maps = mapint.get_anoms(imp=siconc_sample, mask_with_clustid=True, mask_strict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = np.full((3,4), None,dtype = 'object')\n",
    "arrays[0,1:] = sst_maps.listofarrays[1] # moment2 starts 2nd column\n",
    "arrays[1,1:] = sst_maps.listofarrays[0] \n",
    "arrays[2,1:] = siconc_maps.listofarrays[0]\n",
    "arrays[0,0] = sst_maps1.listofarrays[1][0]\n",
    "arrays[1,0] = sst_maps1.listofarrays[0][0]\n",
    "arrays[2,0] = siconc_maps1.listofarrays[0][0]\n",
    "arrays = arrays.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_pcolormesh(array):\n",
    "    \"\"\"Xarray array to usuable things\"\"\"\n",
    "    lats = array.latitude.values # Interpreted as northwest corners (90 is in there)\n",
    "    lons = array.longitude.values # Interpreted as northwest corners (-180 is in there, 180 not)\n",
    "    lats = np.concatenate([lats[[0]] - np.diff(lats)[0], lats], axis = 0) # Adding the sourthern edge \n",
    "    lons = np.concatenate([lons, lons[[-1]] + np.diff(lons)[0]], axis = 0)# Adding the eastern edge\n",
    "    return lons, lats, array.values\n",
    "\n",
    "region = get_nhblock() #\n",
    "extent = (-130, 70, 15,80) # np.array(region[1:])[[1,3,2,0]]  # drop the name and reorder to x0,x1,y0,y1\n",
    "extent_snow = (-180,180,70,90) #np.array(region_snow[1:])[[1,3,2,0]]  # drop the name and reorder to x0,x1,y0,y1\n",
    "extent_21 = (100,200,-40,40)\n",
    "array_crs = ccrs.PlateCarree()\n",
    "proj = ccrs.Robinson(-20)\n",
    "proj_21 = ccrs.Robinson(160)\n",
    "proj_snow = ccrs.Orthographic(0,90)\n",
    "\n",
    "fig = plt.figure(figsize = (12,9))\n",
    "nvars = arrays.shape[1]\n",
    "gs = GridSpec(ncols=nvars + 1, nrows = 4, hspace = .05, wspace = 0.01, width_ratios=[3,3,1.8,0.15])\n",
    "axes = np.full((gs.ncols,nvars),None, dtype = 'object')\n",
    "ims = np.full((gs.ncols,nvars),None, dtype = 'object')\n",
    "for rowind,colind in itertools.product(range(axes.shape[0]),range(axes.shape[1])):\n",
    "    if colind == 2:\n",
    "        axes[rowind,colind] = fig.add_subplot(gs[rowind,colind],projection=proj_snow)\n",
    "        axes[rowind,colind].set_extent(tuple(extent_snow), crs = array_crs)\n",
    "    elif colind == 1:\n",
    "        axes[rowind,colind] = fig.add_subplot(gs[rowind,colind],projection=proj_21)\n",
    "        axes[rowind,colind].set_extent(tuple(extent_21), crs = array_crs)\n",
    "    else:\n",
    "        axes[rowind,colind] = fig.add_subplot(gs[rowind,colind],projection=proj)\n",
    "        axes[rowind,colind].set_extent(tuple(extent), crs = array_crs)\n",
    "    if rowind == 0 or rowind == 1:\n",
    "        vmin, vmax = (-1,1) # anomaly maps\n",
    "        cmap = 'PuOr_r' #'BrBG_r'#'RdBu_r'\n",
    "    elif rowind == 2:\n",
    "        vmin, vmax = (-0.3,0.3) # correlation maps\n",
    "        cmap = 'PuOr_r'#'RdBu_r'\n",
    "    else:\n",
    "        vmin, vmax = (0,8) # scaled multipass\n",
    "        cmap = 'Set1'\n",
    "    #axes[rowind,colind].stock_img()\n",
    "    #axes[rowind,colind].coastlines()\n",
    "    ims[rowind,colind] = axes[rowind,colind].pcolormesh(*data_for_pcolormesh(arrays[rowind,colind]), shading = 'flat', transform = array_crs, cmap = cmap, vmin = vmin, vmax = vmax)\n",
    "    axes[rowind,colind].add_feature(cfeature.LAND, zorder=10, color = 'olivedrab', alpha = 0.8)\n",
    "    \n",
    "cax_m1 = fig.add_subplot(gs[1,-1]) # gs[0:1,-1]\n",
    "cbar_m1 = fig.colorbar(ims[1,-1], cax = cax_m1, orientation = 'vertical', label = 'anomaly [K] or [-]', extend = 'both')\n",
    "cax_corr = fig.add_subplot(gs[2,-1])\n",
    "cbar_corr = fig.colorbar(ims[2,-1], cax = cax_corr, orientation = 'vertical', label = 'correlation',extend = 'both')\n",
    "cax_id = fig.add_subplot(gs[-1,-1])\n",
    "cbar_id = fig.colorbar(ims[-1,-1], cax = cax_id, orientation = 'vertical', label = 'clusterid')\n",
    "\n",
    "plt.savefig('/usr/people/straaten/Pictures/case2015_geo_masked.png', dpi = 140)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VENV",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
