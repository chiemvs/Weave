{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pf\n",
    "from pathlib import Path\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "sys.path.append(os.path.expanduser('~/Documents/Weave'))\n",
    "from Weave.inputoutput import Reader\n",
    "from Weave.clustering import Clustering, Latlons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current params: ms 2000, mcs 4000, allow True, epsilon = 0.0\n",
    "corrpath = Path('/nobackup_1/users/straaten/correlation_cv_spearmanpar_varalpha_strict/t850_nhblock.7.corr.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(corrpath, decode_times = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldseparate = ds['correlation'].sel(lag = -10, fold = 1)\n",
    "fieldwave = ds['correlation'].sel(lag = -7, fold = 0)\n",
    "clusterkwargs = dict(min_cluster_size=2000, #400 \n",
    "                     min_samples=1000, # 1000 good noise reduction\n",
    "                     allow_single_cluster=True,\n",
    "                     cluster_selection_epsilon=0.17, #0.15# Radian distance. Unit = fraction of earth radius. As 2pi * r is the full 2pi radian distance\n",
    "                     metric='haversine',\n",
    "                     core_dist_n_jobs = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldseparate.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldwave.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = Clustering()\n",
    "cl.reshape_and_drop_obs(array = fieldseparate.expand_dims(dim = 'lag', axis = 0), mask = ~fieldseparate.isnull(), min_samples = 700)\n",
    "cl.prepare_for_distance_algorithm(manipulator = Latlons, kwargs = {'to_radians':True})\n",
    "clusters = cl.clustering(clusterclass = HDBSCAN, kwargs = clusterkwargs)\n",
    "clw = Clustering()\n",
    "clw.reshape_and_drop_obs(array = fieldwave.expand_dims(dim = 'lag', axis = 0), mask = ~fieldwave.isnull(), min_samples = 700)\n",
    "clw.prepare_for_distance_algorithm(manipulator = Latlons, kwargs = {'to_radians':True})\n",
    "clustersw = clw.clustering(clusterclass = HDBSCAN, kwargs = clusterkwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.squeeze().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersw.squeeze().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 ms gives a good first noise reduction.\n",
    "At 2000 mcs the clustering for the sparse field seems ok (3 separate duo's, not together). However, the wave field is still subdivided (nothing is together)\n",
    "At 2500, (i.c.w. a reasonable epsilon) sometimes a blob from too far away joins\n",
    "at 3000 mcs the wave fields sees disappearing parts of the wave, still not together\n",
    "at 4000 and 5000 still not together.\n",
    "at 6000 another part disappears\n",
    "0.15 epsilon works for connecting the wave\n",
    "0.1 works only for three parts\n",
    "0.175 works to connect part of another wave\n",
    "Idea: 1000ms 2000mcs 0.17 epsilon (as the bare minimum to connect in these examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets move to SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current params: ms 2000, mcs 4000, allow True, epsilon = 0.0\n",
    "corrpath = Path('/nobackup_1/users/straaten/correlation_cv_spearmanpar_varalpha_strict/sst_nhplus.7.corr.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(corrpath, decode_times = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldmorenoise = ds['correlation'].sel(lag = -28, fold = 0)\n",
    "fieldsignal = ds['correlation'].sel(lag = -12, fold = 1)\n",
    "clusterkwargs = dict(min_cluster_size=1000, #300 worked good without epsilon\n",
    "                     min_samples=300, # 250 good noise reduction without any epsilon, 300 with epsilon\n",
    "                     allow_single_cluster=True,\n",
    "                     cluster_selection_epsilon=0.22, #0.15# Radian distance. Unit = fraction of earth radius. As 2pi * r is the full 2pi radian distance\n",
    "                     metric='haversine',\n",
    "                     core_dist_n_jobs = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldsignal.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldmorenoise.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = Clustering()\n",
    "cl.reshape_and_drop_obs(array = fieldsignal.expand_dims(dim = 'lag', axis = 0), mask = ~fieldsignal.isnull(), min_samples = 700)\n",
    "cl.prepare_for_distance_algorithm(manipulator = Latlons, kwargs = {'to_radians':True})\n",
    "clusters = cl.clustering(clusterclass = HDBSCAN, kwargs = clusterkwargs)\n",
    "cln = Clustering()\n",
    "cln.reshape_and_drop_obs(array = fieldmorenoise.expand_dims(dim = 'lag', axis = 0), mask = ~fieldmorenoise.isnull(), min_samples = 700)\n",
    "cln.prepare_for_distance_algorithm(manipulator = Latlons, kwargs = {'to_radians':True})\n",
    "clustersn = cln.clustering(clusterclass = HDBSCAN, kwargs = clusterkwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.squeeze().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersn.squeeze().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fieldmorenoise.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fieldmorenoise.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sst will have a lower minimum sample size. As just the spatial coherence of anomalies is much less.\n",
    "currently ms 300.\n",
    "Did not make mcs too high. \n",
    "epsilon of 0.2 seems to work out well (6) clusters. But when the merge happens suddenly bit more noisy stuff included. Does ms help? -> well it removes some of the connecting elements. therefore some joined by epsilon split off again. This can again be counteracted with increasing mcs a bit.\n",
    "working with very spotted fields: ms 400, mcs 500, epsilon 0.2\n",
    "does not work so well for a less 'spotted' field \n",
    "therefore: slightly higher epsilon again: 0.22\n",
    "and ms = 300, and mcs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onto a next challenging variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables with different resolution. e.g. snowcover. swvl\n",
    "# Perhaps snowcover with 2-3 big regions and one with only a single."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current params: ms 2000, mcs 4000, allow True, epsilon = 0.0\n",
    "corrpath = Path('/nobackup_1/users/straaten/correlation_cv_spearmanpar_varalpha_strict/snowc_nhmin.21.corr.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(corrpath, decode_times = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldsingle = ds['correlation'].sel(lag = -21, fold = 0) # lag = -52, fold = 3\n",
    "fieldmore = ds['correlation'].sel(lag = -52, fold = 0)\n",
    "clusterkwargs = dict(min_cluster_size= 2500, # 1000 works already okay ish. I believe the single field is not truly single. Only starts to make a difference above 2500.\n",
    "                     min_samples= 1000, # 1000 seems reasonable, (for mcs 200 and 1000) Fields are pretty connected with lots of spots.\n",
    "                     allow_single_cluster=True,\n",
    "                     cluster_selection_epsilon=0.1, ## Radian distance. Unit = fraction of earth radius. As 2pi * r is the full 2pi radian distance\n",
    "                     metric='haversine',\n",
    "                     core_dist_n_jobs = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldsingle.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldmore.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = Clustering()\n",
    "cl.reshape_and_drop_obs(array = fieldsingle.expand_dims(dim = 'lag', axis = 0), mask = ~fieldsingle.isnull(), min_samples = 700)\n",
    "cl.prepare_for_distance_algorithm(manipulator = Latlons, kwargs = {'to_radians':True})\n",
    "clusterss = cl.clustering(clusterclass = HDBSCAN, kwargs = clusterkwargs)\n",
    "clm = Clustering()\n",
    "clm.reshape_and_drop_obs(array = fieldmore.expand_dims(dim = 'lag', axis = 0), mask = ~fieldmore.isnull(), min_samples = 700)\n",
    "clm.prepare_for_distance_algorithm(manipulator = Latlons, kwargs = {'to_radians':True})\n",
    "clustersm = clm.clustering(clusterclass = HDBSCAN, kwargs = clusterkwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clusterss.squeeze().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterss.squeeze().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersm.squeeze().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersm.squeeze().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the epsilon here is slightly less, because this variable specifically focuses also on the polar part of the northern hemisphere where we want to keep things apart (like siberia from america) and because fields are pretty dense. As expected ms and mcs can be a bit larger."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
